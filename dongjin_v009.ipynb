{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from konlpy.tag import Okt\n",
    "from konlpy.utils import partition\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('data/train.csv')\n",
    "test=pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 147871 entries, 0 to 147870\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   comments  147871 non-null  object\n",
      " 1   label     147871 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.3+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39649 entries, 0 to 39648\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   comments  39649 non-null  object\n",
      " 1   label     39649 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 619.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x258804c2820>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['label'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordDict={\"[^ㄱ-ㅎ가-힣 ]\":\" \",'[\\d+]':' ','[ㅡ+]':'','[ㅠ+]':'','[ㅜ+]':'','[ㄱ-ㅎ]':'','[ㅏ-ㅣ]':'','ᆢᆢ':''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in wordDict.items():\n",
    "    train['comments']=train.comments.str.replace(i,j)\n",
    "    test['comments']=test.comments.str.replace(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw(x):\n",
    "    simdict={'추카':'축하'\n",
    "            }\n",
    "    for index,word in simdict.items():\n",
    "        return re.sub(index,word,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['comments']=train.comments.apply(cw)\n",
    "test['comments']=test.comments.apply(cw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=['아','휴','아이구','아이쿠','아이고','어','나','우리','저희','따라','의해','을','를','에','의','가','으로','로','에게','뿐이다','의거하여','근거하여','입각하여','기준으로',\n",
    "'예하면','예를 들면','예를 들자면','저','소인','소생','저희','지말고','하지마','하지마라','다른','물론','또한','그리고','비길수 없다','해서는 안된다','뿐만 아니라','만이 아니다',\n",
    "'만은 아니다','막론하고','관계없이','그치지 않다','그러나','그런데','하지만','든간에','논하지 않다','따지지 않다','설사','비록','더라도','아니면','만' '못하다','하는 편이 낫다',\n",
    "'불문하고','향하여','향해서','향하다','쪽으로','틈타','이용하여','타다','오르다','제외하고','이 외에','이 밖에','하여야','비로소','한다면' '몰라도','외에도','이곳','여기','부터',\n",
    "'기점으로,따라서','할 생각이다','하려고하다','이리하여','그리하여','그렇게' '함으로써','하지만','일때','할때','앞에서','중에서','보는데서','으로써','로써','까지','해야한다',\n",
    "'일것이다','반드시','할줄알다','할수있다','할수있어','임에 틀림없다','한다면','등','등등','제','겨우','단지','다만','할뿐','딩동','댕그','대해서','대하여','대하면','훨씬','얼마나',\n",
    "'얼마만큼','얼마큼','남짓','여','얼마간','약간','다소','좀','조금','다수','몇','얼마','지만','하물며','또한','그러나','그렇지만','하지만','이외에도','대해 말하자면','뿐이다','다음에',\n",
    "'반대로','반대로 말하자면','이와 반대로','바꾸어서 말하면','바꾸어서 한다면','만약','그렇지않으면','까악','툭','딱','삐걱거리다','보드득','비걱거리다','꽈당','응당','해야한다',\n",
    "'에 가서','각','각각','여러분','각종','각자','제각기','하도록하다','와','과','그러므로','그래서','고로','한 까닭에','하기 때문에','거니와','이지만','대하여','관하여','관한','과연',\n",
    "'실로','아니나다를가','생각한대로','진짜로','한적이있다','하곤하였다','하','하하','허허','아하','거바','와','오','왜','어째서','무엇때문에','어찌','하겠는가','무슨','어디','어느곳',\n",
    "'더군다나','하물며','더욱이는','어느때','언제','야','이봐','어이','여보시오','흐흐','흥','휴','헉헉','헐떡헐떡','영차','여차','어기여차','끙끙','아야','앗','아야','콸콸','졸졸','좍좍','뚝뚝',\n",
    "'주룩주룩','솨','우르르','그래도','또','그리고','바꾸어말하면','바꾸어말하자면','혹은','혹시','답다','및','그에 따르는','때가 되어','즉','지든지','설령','가령','하더라도','할지라도',\n",
    "'일지라도','지든지','몇','거의,하마터면','인젠','이젠','된바에야','된이상','만큼','어찌됏든','그위에','게다가','점에서 보아','비추어 보아','고려하면','하게될것이다','일것이다',\n",
    "'비교적','좀','보다더','비하면','시키다','하게하다','할만하다','의해서','연이서','이어서','잇따라','뒤따라','뒤이어','결국','의지하여','기대여','통하여','자마자','더욱더','불구하고',\n",
    "'얼마든지','마음대로','주저하지 않고','곧','즉시','바로','당장','하자마자','밖에' '안된다','하면된다','그래','그렇지','요컨대','다시 말하자면','바꿔 말하면','즉','구체적으로',\n",
    "'말하자면','시작하여','시초에','이상','허','헉','허걱','바와같이','해도좋다','해도된다','게다가','더구나','하물며','와르르','팍','퍽','펄렁','동안','이래','하고있었다','이었다','에서',\n",
    "'로부터','까지','예하면','했어요','해요','함께','같이','더불어','마저','마저도','양자','모두','습니다','가까스로','하려고하다','즈음하여','다른','다른 방면으로','해봐요','습니까',\n",
    "'했어요','말할것도 없고','무릎쓰고','개의치않고','하는것만 못하다','하는것이 낫다','매','매번','들','모','어느것','어느','로써','갖고말하자면','어디','어느쪽','어느것','어느해',\n",
    "'어느 년도','라' '해도','언젠가','어떤것','어느것','저기','저쪽','저것','그때','그럼','그러면','요만한걸','그래','그때','저것만큼','그저','이르기까지','할 줄 안다','할 힘이' '있다',\n",
    "'너','너희','당신','어찌','설마','차라리','할지언정','할지라도','할망정','할지언정','구토하다','게우다','토하다','메쓰겁다','옆사람','퉤','쳇','의거하여','근거하여','의해','따라',\n",
    "'힘입어','그','다음','버금','두번째로','기타','첫번째로','나머지는','그중에서','견지에서','형식으로 쓰여','입장에서','위해서','단지','의해되다','하도록시키다','뿐만아니라',\n",
    "'반대로','전후','전자','앞의것','잠시','잠깐','하면서','그렇지만','다음에','그러한즉','그런즉','남들','아무거나','어찌하든지','같다','비슷하다','예컨대','이럴정도로','어떻게',\n",
    "'만약','만일','위에서' '서술한바와같이','인 듯하다','하지 않는다면','만약에','무엇','무슨','어느','어떤','아래윗','조차','한데','그럼에도 불구하고','여전히','심지어','까지도',\n",
    "'조차도','하지 않도록','않기 위하여','때','시각','무렵','시간','동안','어때','어떠한','하여금','네','예','우선','누구','누가' '알겠는가','아무도','줄은모른다','줄은 몰랏다','하는 김에',\n",
    "'겸사겸사','하는바','그런 까닭에','한 이유는','그러니','그러니까','때문에','그','너희','그들','너희들','타인','것','것들','너','위하여','공동으로','동시에','하기 위하여','어찌하여',\n",
    "'무엇때문에','붕붕','윙윙','나','우리','엉엉','휘익','윙윙','오호','아하','어쨋든','만 못하다','하기보다는','차라리,하는 편이 낫다','흐흐','놀라다','상대적으로 말하자면','마치',\n",
    "'아니라면','쉿','그렇지 않으면','그렇지' '않다면','안 그러면','아니었다면','하든지','아니면','이라면','좋아','알았어','하는것도','그만이다','어쩔수 없다','하나','일','일반적으로',\n",
    "'일단','한켠으로는','오자마자','이렇게되면','이와같다면','전부','한마디','한항목','근거로','하기에','아울러','하지 않도록','않기 위해서','이르기까지','이 되다','로 인하여',\n",
    "'까닭으로','이유만으로','이로 인하여','그래서','이 때문에','그러므로','그런 까닭에','알 수 있다','결론을 낼 수 있다','으로 인하여','있다','어떤것','관계가 있다','관련이 있다',\n",
    "'연관되다','어떤것들','에 대해','이리하여','그리하여','여부','하기보다는','하느니','하면 할수록','운운','이러이러하다','하구나','하도다','다시말하면','다음으로','에 있다',\n",
    "'에 달려 있다','우리','우리들','오히려','하기는한데','어떻게','어떻해','어찌됏어','어때','어째서','본대로','자','이','이쪽','여기','이것','이번','이렇게말하자면','이런','이러한',\n",
    "'이와 같은','요만큼','요만한 것','얼마 안 되는 것','이만큼','이 정도의','이렇게 많은 것','이와 같다','이때','이렇구나','것과 같이','끼익','삐걱,따위','와 같은 사람들',\n",
    "'부류의 사람들','왜냐하면','중의하나','오직','오로지','에 한하다','하기만 하면','도착하다','까지 미치다','도달하다','정도에 이르다','할 지경이다','결과에 이르다','관해서는',\n",
    "'여러분','하고 있다','한 후','혼자','자기','자기집','자신','우에' '종합한것과같이','총적으로' '보면','총적으로' '말하면','총적으로','대로 하다','으로서','참','그만이다','할 따름이다','쿵',\n",
    "'탕탕','쾅쾅','둥둥','봐','봐라','아이야','아니','와아','응','아이','참나','년','월','일','령','영','일','이','삼','사','오','육','륙','칠','팔','구','이천육','이천칠','이천팔','이천구','하나','둘','셋',\n",
    "'넷','다섯','여섯','일곱','여덟','아홉','령','영']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# konlpyList=['okt','']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1 #단어 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "okt=Okt()\n",
    "wordList=[]\n",
    "word_index={}\n",
    "wordCount={}\n",
    "train['okt']='0'\n",
    "for index ,sentencs in enumerate(train['comments']):\n",
    "    words=okt.morphs(sentencs,norm=True,stem=True)   \n",
    "    train['okt'].iloc[index]=words\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            if len(word) >= n:\n",
    "                if word not in wordList:\n",
    "                    wordCount[word]=1\n",
    "                    wordList.append(word)\n",
    "                else:\n",
    "                    wordCount[word]=wordCount[word]+1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['okt']='0'\n",
    "for index ,sentencs in enumerate(test['comments']):\n",
    "    words=okt.morphs(sentencs,norm=True,stem=True)\n",
    "    test['okt'].iloc[index]=words   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount_df=pd.DataFrame([[i,j] for i,j in wordCount.items()],columns=['word', 'index'])\n",
    "wordCount_df.to_csv('wordCount_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount_df=pd.read_csv('wordCount_df.csv',)\n",
    "wordCount={}\n",
    "for i in range(len(wordCount_df)):\n",
    "    wordCount[wordCount_df['word'].iloc[i]]=wordCount_df['index'].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount_df.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=30 #빈도수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList=[]\n",
    "word_index={}\n",
    "for index ,word in enumerate(wordCount.keys()):\n",
    "    if wordCount[word]>= m : \n",
    "        word_index[word]=len(wordList)\n",
    "        wordList.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Term Matrix , One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dtm_array=[]\n",
    "train_ohe_array=[]\n",
    "for corpus in train['okt']:\n",
    "    temp1=[0]*len(wordList)\n",
    "    temp2=[0]*len(wordList)\n",
    "    for word in corpus:\n",
    "        if word in wordList:\n",
    "            temp1[word_index[word]]=+1\n",
    "            temp2[word_index[word]]=1\n",
    "    train_dtm_array.append(temp1)\n",
    "    train_ohe_array.append(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dtm=pd.DataFrame(train_dtm_array,columns=word_index.keys())\n",
    "train_ohe=pd.DataFrame(train_ohe_array,columns=word_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dtm.to_csv('train_dtm.csv',index=False)\n",
    "train_ohe.to_csv('train_ohe.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dtm_array=[]\n",
    "test_ohe_array=[]\n",
    "for corpus in test['okt']:\n",
    "    temp1=[0]*len(wordList)\n",
    "    temp2=[0]*len(wordList)\n",
    "    for word in corpus:\n",
    "        if word in wordList:\n",
    "            temp1[word_index[word]]=+1\n",
    "            temp2[word_index[word]]=1\n",
    "    test_dtm_array.append(temp1)\n",
    "    test_ohe_array.append(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dtm=pd.DataFrame(test_dtm_array,columns=word_index.keys())\n",
    "test_ohe=pd.DataFrame(test_ohe_array,columns=word_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dtm.to_csv('test_dtm.csv',index=False)\n",
    "test_ohe.to_csv('test_ohe.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xTrain yTrain xTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dtm=pd.read_csv('train_dtm.csv')\n",
    "train_ohe=pd.read_csv('train_ohe.csv')\n",
    "test_dtm=pd.read_csv('test_dtm.csv')\n",
    "test_ohe=pd.read_csv('test_ohe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain=train_ohe.values\n",
    "yTrain=train['label'].values\n",
    "xTest=test_ohe.values\n",
    "yTest=test['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalNB()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=CategoricalNB()\n",
    "model.fit(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_NB=model.predict(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9062358406989877"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(xTrain , yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.904814749426215"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['pred_NB']=pred_NB\n",
    "(test['label']==test['pred_NB']).sum()/test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(dtm):\n",
    "    n=dtm.shape[0]\n",
    "    c=(dtm!=0).sum(axis=0)\n",
    "    m=np.log(n/(c+1))\n",
    "    return m*dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ifidf=tfidf(xTrain)\n",
    "test_ifidf=tfidf(xTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr(y_i, y):\n",
    "    p = train_dtm[y==y_i].sum(0)\n",
    "    return (p+1) / ((y==y_i).sum()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mdl(y):\n",
    "    y = y.values\n",
    "    r = np.log(pr(1,y) / pr(0,y))\n",
    "    m = LogisticRegression()\n",
    "    x_nb = train_dtm.multiply(r)\n",
    "    return m.fit(x_nb, y), r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "m,r = get_mdl(train['label'])\n",
    "preds=m.predict_proba(test_dtm.multiply(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9286488940452471"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_NB_SVM=[]\n",
    "for i in preds:\n",
    "    pred_NB_SVM.append(i.argmax())\n",
    "\n",
    "test['pred_NB_SVM']=pred_NB_SVM\n",
    "(test['label']==test['pred_NB_SVM']).sum()/test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(2048,input_shape=(xTrain.shape[1],) ,activation='relu'))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(2,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       ...,\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['none']=train['label']==0\n",
    "train['hate']=train['label']==1\n",
    "yTrain=train[['none','hate']].values\n",
    "yTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = xTrain[:2000]\n",
    "partial_x_train = xTrain[2000:]\n",
    "\n",
    "y_val = yTrain[:2000]\n",
    "partial_y_train = yTrain[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "285/285 [==============================] - 13s 46ms/step - loss: 0.6905 - accuracy: 0.5308 - val_loss: 0.6880 - val_accuracy: 0.5565\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 13s 45ms/step - loss: 0.6815 - accuracy: 0.6093 - val_loss: 0.6742 - val_accuracy: 0.6785\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 13s 45ms/step - loss: 0.6586 - accuracy: 0.7470 - val_loss: 0.6428 - val_accuracy: 0.7945\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 13s 45ms/step - loss: 0.6086 - accuracy: 0.8065 - val_loss: 0.5734 - val_accuracy: 0.8000\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 13s 45ms/step - loss: 0.5115 - accuracy: 0.8157 - val_loss: 0.4615 - val_accuracy: 0.8110\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 13s 46ms/step - loss: 0.4026 - accuracy: 0.8401 - val_loss: 0.3686 - val_accuracy: 0.8410\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 13s 47ms/step - loss: 0.3282 - accuracy: 0.8669 - val_loss: 0.3112 - val_accuracy: 0.8685\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 13s 46ms/step - loss: 0.2840 - accuracy: 0.8849 - val_loss: 0.2778 - val_accuracy: 0.8870\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 13s 46ms/step - loss: 0.2572 - accuracy: 0.8957 - val_loss: 0.2560 - val_accuracy: 0.8985\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 13s 46ms/step - loss: 0.2396 - accuracy: 0.9023 - val_loss: 0.2418 - val_accuracy: 0.9065\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 13s 47ms/step - loss: 0.2269 - accuracy: 0.9075 - val_loss: 0.2312 - val_accuracy: 0.9095\n",
      "Epoch 12/100\n",
      "285/285 [==============================] - 13s 47ms/step - loss: 0.2170 - accuracy: 0.9115 - val_loss: 0.2218 - val_accuracy: 0.9130\n",
      "Epoch 13/100\n",
      "285/285 [==============================] - 13s 47ms/step - loss: 0.2090 - accuracy: 0.9145 - val_loss: 0.2156 - val_accuracy: 0.9175\n",
      "Epoch 14/100\n",
      "285/285 [==============================] - 13s 47ms/step - loss: 0.2021 - accuracy: 0.9173 - val_loss: 0.2096 - val_accuracy: 0.9220\n",
      "Epoch 15/100\n",
      "285/285 [==============================] - 13s 47ms/step - loss: 0.1961 - accuracy: 0.9197 - val_loss: 0.2042 - val_accuracy: 0.9230\n",
      "Epoch 16/100\n",
      "285/285 [==============================] - 13s 47ms/step - loss: 0.1907 - accuracy: 0.9217 - val_loss: 0.2003 - val_accuracy: 0.9260\n",
      "Epoch 17/100\n",
      "285/285 [==============================] - 13s 47ms/step - loss: 0.1860 - accuracy: 0.9238 - val_loss: 0.1966 - val_accuracy: 0.9255\n",
      "Epoch 18/100\n",
      "285/285 [==============================] - 13s 47ms/step - loss: 0.1818 - accuracy: 0.9257 - val_loss: 0.1932 - val_accuracy: 0.9285\n",
      "Epoch 19/100\n",
      "285/285 [==============================] - 14s 47ms/step - loss: 0.1780 - accuracy: 0.9271 - val_loss: 0.1908 - val_accuracy: 0.9290\n",
      "Epoch 20/100\n",
      "285/285 [==============================] - 14s 47ms/step - loss: 0.1745 - accuracy: 0.9286 - val_loss: 0.1890 - val_accuracy: 0.9295\n",
      "Epoch 21/100\n",
      "285/285 [==============================] - 14s 47ms/step - loss: 0.1713 - accuracy: 0.9302 - val_loss: 0.1870 - val_accuracy: 0.9275\n",
      "Epoch 22/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1682 - accuracy: 0.9316 - val_loss: 0.1888 - val_accuracy: 0.9255\n",
      "Epoch 23/100\n",
      "285/285 [==============================] - 14s 47ms/step - loss: 0.1653 - accuracy: 0.9329 - val_loss: 0.1843 - val_accuracy: 0.9290\n",
      "Epoch 24/100\n",
      "285/285 [==============================] - 14s 47ms/step - loss: 0.1626 - accuracy: 0.9346 - val_loss: 0.1837 - val_accuracy: 0.9280\n",
      "Epoch 25/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1601 - accuracy: 0.9356 - val_loss: 0.1826 - val_accuracy: 0.9290\n",
      "Epoch 26/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1576 - accuracy: 0.9365 - val_loss: 0.1829 - val_accuracy: 0.9275\n",
      "Epoch 27/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1551 - accuracy: 0.9378 - val_loss: 0.1809 - val_accuracy: 0.9270\n",
      "Epoch 28/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1528 - accuracy: 0.9386 - val_loss: 0.1816 - val_accuracy: 0.9260\n",
      "Epoch 29/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1506 - accuracy: 0.9396 - val_loss: 0.1804 - val_accuracy: 0.9265\n",
      "Epoch 30/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1485 - accuracy: 0.9399 - val_loss: 0.1811 - val_accuracy: 0.9270\n",
      "Epoch 31/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1465 - accuracy: 0.9412 - val_loss: 0.1803 - val_accuracy: 0.9250\n",
      "Epoch 32/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1442 - accuracy: 0.9423 - val_loss: 0.1804 - val_accuracy: 0.9235\n",
      "Epoch 33/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1422 - accuracy: 0.9430 - val_loss: 0.1811 - val_accuracy: 0.9220\n",
      "Epoch 34/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1404 - accuracy: 0.9434 - val_loss: 0.1802 - val_accuracy: 0.9270\n",
      "Epoch 35/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1383 - accuracy: 0.9448 - val_loss: 0.1794 - val_accuracy: 0.9280\n",
      "Epoch 36/100\n",
      "285/285 [==============================] - 14s 49ms/step - loss: 0.1366 - accuracy: 0.9452 - val_loss: 0.1801 - val_accuracy: 0.9275\n",
      "Epoch 37/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1348 - accuracy: 0.9459 - val_loss: 0.1800 - val_accuracy: 0.9275\n",
      "Epoch 38/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1329 - accuracy: 0.9465 - val_loss: 0.1819 - val_accuracy: 0.9255\n",
      "Epoch 39/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1311 - accuracy: 0.9478 - val_loss: 0.1801 - val_accuracy: 0.9260\n",
      "Epoch 40/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1293 - accuracy: 0.9483 - val_loss: 0.1813 - val_accuracy: 0.9265\n",
      "Epoch 41/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1275 - accuracy: 0.9495 - val_loss: 0.1827 - val_accuracy: 0.9270\n",
      "Epoch 42/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1255 - accuracy: 0.9505 - val_loss: 0.1813 - val_accuracy: 0.9250\n",
      "Epoch 43/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1241 - accuracy: 0.9509 - val_loss: 0.1829 - val_accuracy: 0.9255\n",
      "Epoch 44/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1220 - accuracy: 0.9518 - val_loss: 0.1838 - val_accuracy: 0.9255\n",
      "Epoch 45/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1204 - accuracy: 0.9525 - val_loss: 0.1833 - val_accuracy: 0.9255\n",
      "Epoch 46/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1184 - accuracy: 0.9531 - val_loss: 0.1889 - val_accuracy: 0.9245\n",
      "Epoch 47/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1169 - accuracy: 0.9537 - val_loss: 0.1828 - val_accuracy: 0.9260\n",
      "Epoch 48/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1154 - accuracy: 0.9548 - val_loss: 0.1832 - val_accuracy: 0.9260\n",
      "Epoch 49/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1135 - accuracy: 0.9552 - val_loss: 0.1852 - val_accuracy: 0.9255\n",
      "Epoch 50/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1123 - accuracy: 0.9559 - val_loss: 0.1842 - val_accuracy: 0.9240\n",
      "Epoch 51/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1103 - accuracy: 0.9563 - val_loss: 0.1837 - val_accuracy: 0.9240\n",
      "Epoch 52/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1089 - accuracy: 0.9578 - val_loss: 0.1842 - val_accuracy: 0.9255\n",
      "Epoch 53/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1068 - accuracy: 0.9579 - val_loss: 0.1892 - val_accuracy: 0.9250\n",
      "Epoch 54/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1056 - accuracy: 0.9584 - val_loss: 0.1860 - val_accuracy: 0.9235\n",
      "Epoch 55/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1038 - accuracy: 0.9594 - val_loss: 0.1874 - val_accuracy: 0.9285\n",
      "Epoch 56/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1020 - accuracy: 0.9605 - val_loss: 0.1860 - val_accuracy: 0.9265\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1010 - accuracy: 0.9606 - val_loss: 0.2011 - val_accuracy: 0.9240\n",
      "Epoch 58/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.1011 - accuracy: 0.9600 - val_loss: 0.1885 - val_accuracy: 0.9250\n",
      "Epoch 59/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.0984 - accuracy: 0.9617 - val_loss: 0.2007 - val_accuracy: 0.9245\n",
      "Epoch 60/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.0969 - accuracy: 0.9623 - val_loss: 0.1869 - val_accuracy: 0.9260\n",
      "Epoch 61/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.0959 - accuracy: 0.9621 - val_loss: 0.1900 - val_accuracy: 0.9255\n",
      "Epoch 62/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.0937 - accuracy: 0.9637 - val_loss: 0.1944 - val_accuracy: 0.9280\n",
      "Epoch 63/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.0956 - accuracy: 0.9620 - val_loss: 0.1892 - val_accuracy: 0.9275\n",
      "Epoch 64/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.0919 - accuracy: 0.9640 - val_loss: 0.1932 - val_accuracy: 0.9250\n",
      "Epoch 65/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.0953 - accuracy: 0.9624 - val_loss: 0.1939 - val_accuracy: 0.9265\n",
      "Epoch 66/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.0921 - accuracy: 0.9635 - val_loss: 0.1928 - val_accuracy: 0.9265\n",
      "Epoch 67/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.0912 - accuracy: 0.9642 - val_loss: 0.1952 - val_accuracy: 0.9260\n",
      "Epoch 68/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.0890 - accuracy: 0.9647 - val_loss: 0.2010 - val_accuracy: 0.9235\n",
      "Epoch 69/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.0907 - accuracy: 0.9641 - val_loss: 0.1903 - val_accuracy: 0.9260\n",
      "Epoch 70/100\n",
      "285/285 [==============================] - 14s 49ms/step - loss: 0.0923 - accuracy: 0.9635 - val_loss: 0.1994 - val_accuracy: 0.9260\n",
      "Epoch 71/100\n",
      "285/285 [==============================] - 14s 49ms/step - loss: 0.0926 - accuracy: 0.9632 - val_loss: 0.2459 - val_accuracy: 0.9140\n",
      "Epoch 72/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.0843 - accuracy: 0.9669 - val_loss: 0.2019 - val_accuracy: 0.9265\n",
      "Epoch 73/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.0893 - accuracy: 0.9646 - val_loss: 0.1954 - val_accuracy: 0.9265\n",
      "Epoch 74/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.0860 - accuracy: 0.9663 - val_loss: 0.1951 - val_accuracy: 0.9260\n",
      "Epoch 75/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.0845 - accuracy: 0.9668 - val_loss: 0.2646 - val_accuracy: 0.9090\n",
      "Epoch 76/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.0901 - accuracy: 0.9637 - val_loss: 0.2080 - val_accuracy: 0.9245\n",
      "Epoch 77/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.0799 - accuracy: 0.9693 - val_loss: 0.1949 - val_accuracy: 0.9265\n",
      "Epoch 78/100\n",
      "285/285 [==============================] - 14s 49ms/step - loss: 0.0864 - accuracy: 0.9659 - val_loss: 0.2080 - val_accuracy: 0.9220\n",
      "Epoch 79/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.0824 - accuracy: 0.9671 - val_loss: 0.2466 - val_accuracy: 0.9145\n",
      "Epoch 80/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.0844 - accuracy: 0.9668 - val_loss: 0.2005 - val_accuracy: 0.9255\n",
      "Epoch 81/100\n",
      "285/285 [==============================] - 14s 49ms/step - loss: 0.0815 - accuracy: 0.9681 - val_loss: 0.2549 - val_accuracy: 0.9150\n",
      "Epoch 82/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.0823 - accuracy: 0.9672 - val_loss: 0.1986 - val_accuracy: 0.9245\n",
      "Epoch 83/100\n",
      "285/285 [==============================] - 14s 49ms/step - loss: 0.0745 - accuracy: 0.9706 - val_loss: 0.1983 - val_accuracy: 0.9295\n",
      "Epoch 84/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.0768 - accuracy: 0.9701 - val_loss: 0.2168 - val_accuracy: 0.9230\n",
      "Epoch 85/100\n",
      "285/285 [==============================] - 14s 49ms/step - loss: 0.0842 - accuracy: 0.9669 - val_loss: 0.2105 - val_accuracy: 0.9280\n",
      "Epoch 86/100\n",
      "285/285 [==============================] - 14s 49ms/step - loss: 0.0734 - accuracy: 0.9716 - val_loss: 0.2260 - val_accuracy: 0.9210\n",
      "Epoch 87/100\n",
      "285/285 [==============================] - 14s 49ms/step - loss: 0.0756 - accuracy: 0.9705 - val_loss: 0.2020 - val_accuracy: 0.9275\n",
      "Epoch 88/100\n",
      "285/285 [==============================] - 14s 49ms/step - loss: 0.0761 - accuracy: 0.9700 - val_loss: 0.2155 - val_accuracy: 0.9245\n",
      "Epoch 89/100\n",
      "285/285 [==============================] - 14s 49ms/step - loss: 0.0804 - accuracy: 0.9683 - val_loss: 0.2193 - val_accuracy: 0.9220\n",
      "Epoch 90/100\n",
      "285/285 [==============================] - 14s 49ms/step - loss: 0.0692 - accuracy: 0.9731 - val_loss: 0.2009 - val_accuracy: 0.9265\n",
      "Epoch 91/100\n",
      "285/285 [==============================] - 14s 49ms/step - loss: 0.0745 - accuracy: 0.9711 - val_loss: 0.2105 - val_accuracy: 0.9250\n",
      "Epoch 92/100\n",
      "285/285 [==============================] - 14s 49ms/step - loss: 0.0673 - accuracy: 0.9742 - val_loss: 0.1983 - val_accuracy: 0.9280\n",
      "Epoch 93/100\n",
      "285/285 [==============================] - 14s 49ms/step - loss: 0.0673 - accuracy: 0.9737 - val_loss: 0.1978 - val_accuracy: 0.9280\n",
      "Epoch 94/100\n",
      "285/285 [==============================] - 14s 49ms/step - loss: 0.0764 - accuracy: 0.9701 - val_loss: 0.2089 - val_accuracy: 0.9280\n",
      "Epoch 95/100\n",
      "285/285 [==============================] - 14s 49ms/step - loss: 0.0750 - accuracy: 0.9718 - val_loss: 0.2143 - val_accuracy: 0.9260\n",
      "Epoch 96/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.0683 - accuracy: 0.9735 - val_loss: 0.2076 - val_accuracy: 0.9275\n",
      "Epoch 97/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.0655 - accuracy: 0.9746 - val_loss: 0.1998 - val_accuracy: 0.9300\n",
      "Epoch 98/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.0611 - accuracy: 0.9761 - val_loss: 0.2047 - val_accuracy: 0.9265\n",
      "Epoch 99/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 0.0663 - accuracy: 0.9741 - val_loss: 0.2113 - val_accuracy: 0.9250\n",
      "Epoch 100/100\n",
      "226/285 [======================>.......] - ETA: 2s - loss: 0.0601 - accuracy: 0.9765"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss= history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo',label=\"Training loss\" )\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.clf() #그래프 초기화 \n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('RNN_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(xTrain,yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_RNN=model.predict(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_RNN_list=[]\n",
    "for i in range(len(pred_RNN)):\n",
    "    pred_RNN_list.append(pred_RNN[i].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['pred_RNN']=pred_RNN_list\n",
    "(test['label']==test['pred_RNN']).sum()/test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
