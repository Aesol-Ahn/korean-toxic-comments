{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from konlpy.tag import Okt\n",
    "from konlpy.utils import partition\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('data/train.csv')\n",
    "test=pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 147871 entries, 0 to 147870\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   comments  147871 non-null  object\n",
      " 1   label     147871 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.3+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39649 entries, 0 to 39648\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   comments  39649 non-null  object\n",
      " 1   label     39649 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 619.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train[:20000]\n",
    "test=test[:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fc8a042a30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['label'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordDict={\"[^ㄱ-ㅎ가-힣 ]\":\" \",'[\\d+]':' ','[ㅡ+]':'','[ㅠ+]':'','[ㅜ+]':'','[ㄱ-ㅎ]':'','[ㅏ-ㅣ]':'','ᆢᆢ':''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in wordDict.items():\n",
    "    train['comments']=train.comments.str.replace(i,j)\n",
    "    test['comments']=test.comments.str.replace(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw(x):\n",
    "    simdict={'추카':'축하'\n",
    "            }\n",
    "    for index,word in simdict.items():\n",
    "        return re.sub(index,word,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['comments']=train.comments.apply(cw)\n",
    "test['comments']=test.comments.apply(cw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=['아','휴','아이구','아이쿠','아이고','어','나','우리','저희','따라','의해','을','를','에','의','가','으로','로','에게','뿐이다','의거하여','근거하여','입각하여','기준으로',\n",
    "'예하면','예를 들면','예를 들자면','저','소인','소생','저희','지말고','하지마','하지마라','다른','물론','또한','그리고','비길수 없다','해서는 안된다','뿐만 아니라','만이 아니다',\n",
    "'만은 아니다','막론하고','관계없이','그치지 않다','그러나','그런데','하지만','든간에','논하지 않다','따지지 않다','설사','비록','더라도','아니면','만' '못하다','하는 편이 낫다',\n",
    "'불문하고','향하여','향해서','향하다','쪽으로','틈타','이용하여','타다','오르다','제외하고','이 외에','이 밖에','하여야','비로소','한다면' '몰라도','외에도','이곳','여기','부터',\n",
    "'기점으로,따라서','할 생각이다','하려고하다','이리하여','그리하여','그렇게' '함으로써','하지만','일때','할때','앞에서','중에서','보는데서','으로써','로써','까지','해야한다',\n",
    "'일것이다','반드시','할줄알다','할수있다','할수있어','임에 틀림없다','한다면','등','등등','제','겨우','단지','다만','할뿐','딩동','댕그','대해서','대하여','대하면','훨씬','얼마나',\n",
    "'얼마만큼','얼마큼','남짓','여','얼마간','약간','다소','좀','조금','다수','몇','얼마','지만','하물며','또한','그러나','그렇지만','하지만','이외에도','대해 말하자면','뿐이다','다음에',\n",
    "'반대로','반대로 말하자면','이와 반대로','바꾸어서 말하면','바꾸어서 한다면','만약','그렇지않으면','까악','툭','딱','삐걱거리다','보드득','비걱거리다','꽈당','응당','해야한다',\n",
    "'에 가서','각','각각','여러분','각종','각자','제각기','하도록하다','와','과','그러므로','그래서','고로','한 까닭에','하기 때문에','거니와','이지만','대하여','관하여','관한','과연',\n",
    "'실로','아니나다를가','생각한대로','진짜로','한적이있다','하곤하였다','하','하하','허허','아하','거바','와','오','왜','어째서','무엇때문에','어찌','하겠는가','무슨','어디','어느곳',\n",
    "'더군다나','하물며','더욱이는','어느때','언제','야','이봐','어이','여보시오','흐흐','흥','휴','헉헉','헐떡헐떡','영차','여차','어기여차','끙끙','아야','앗','아야','콸콸','졸졸','좍좍','뚝뚝',\n",
    "'주룩주룩','솨','우르르','그래도','또','그리고','바꾸어말하면','바꾸어말하자면','혹은','혹시','답다','및','그에 따르는','때가 되어','즉','지든지','설령','가령','하더라도','할지라도',\n",
    "'일지라도','지든지','몇','거의,하마터면','인젠','이젠','된바에야','된이상','만큼','어찌됏든','그위에','게다가','점에서 보아','비추어 보아','고려하면','하게될것이다','일것이다',\n",
    "'비교적','좀','보다더','비하면','시키다','하게하다','할만하다','의해서','연이서','이어서','잇따라','뒤따라','뒤이어','결국','의지하여','기대여','통하여','자마자','더욱더','불구하고',\n",
    "'얼마든지','마음대로','주저하지 않고','곧','즉시','바로','당장','하자마자','밖에' '안된다','하면된다','그래','그렇지','요컨대','다시 말하자면','바꿔 말하면','즉','구체적으로',\n",
    "'말하자면','시작하여','시초에','이상','허','헉','허걱','바와같이','해도좋다','해도된다','게다가','더구나','하물며','와르르','팍','퍽','펄렁','동안','이래','하고있었다','이었다','에서',\n",
    "'로부터','까지','예하면','했어요','해요','함께','같이','더불어','마저','마저도','양자','모두','습니다','가까스로','하려고하다','즈음하여','다른','다른 방면으로','해봐요','습니까',\n",
    "'했어요','말할것도 없고','무릎쓰고','개의치않고','하는것만 못하다','하는것이 낫다','매','매번','들','모','어느것','어느','로써','갖고말하자면','어디','어느쪽','어느것','어느해',\n",
    "'어느 년도','라' '해도','언젠가','어떤것','어느것','저기','저쪽','저것','그때','그럼','그러면','요만한걸','그래','그때','저것만큼','그저','이르기까지','할 줄 안다','할 힘이' '있다',\n",
    "'너','너희','당신','어찌','설마','차라리','할지언정','할지라도','할망정','할지언정','구토하다','게우다','토하다','메쓰겁다','옆사람','퉤','쳇','의거하여','근거하여','의해','따라',\n",
    "'힘입어','그','다음','버금','두번째로','기타','첫번째로','나머지는','그중에서','견지에서','형식으로 쓰여','입장에서','위해서','단지','의해되다','하도록시키다','뿐만아니라',\n",
    "'반대로','전후','전자','앞의것','잠시','잠깐','하면서','그렇지만','다음에','그러한즉','그런즉','남들','아무거나','어찌하든지','같다','비슷하다','예컨대','이럴정도로','어떻게',\n",
    "'만약','만일','위에서' '서술한바와같이','인 듯하다','하지 않는다면','만약에','무엇','무슨','어느','어떤','아래윗','조차','한데','그럼에도 불구하고','여전히','심지어','까지도',\n",
    "'조차도','하지 않도록','않기 위하여','때','시각','무렵','시간','동안','어때','어떠한','하여금','네','예','우선','누구','누가' '알겠는가','아무도','줄은모른다','줄은 몰랏다','하는 김에',\n",
    "'겸사겸사','하는바','그런 까닭에','한 이유는','그러니','그러니까','때문에','그','너희','그들','너희들','타인','것','것들','너','위하여','공동으로','동시에','하기 위하여','어찌하여',\n",
    "'무엇때문에','붕붕','윙윙','나','우리','엉엉','휘익','윙윙','오호','아하','어쨋든','만 못하다','하기보다는','차라리,하는 편이 낫다','흐흐','놀라다','상대적으로 말하자면','마치',\n",
    "'아니라면','쉿','그렇지 않으면','그렇지' '않다면','안 그러면','아니었다면','하든지','아니면','이라면','좋아','알았어','하는것도','그만이다','어쩔수 없다','하나','일','일반적으로',\n",
    "'일단','한켠으로는','오자마자','이렇게되면','이와같다면','전부','한마디','한항목','근거로','하기에','아울러','하지 않도록','않기 위해서','이르기까지','이 되다','로 인하여',\n",
    "'까닭으로','이유만으로','이로 인하여','그래서','이 때문에','그러므로','그런 까닭에','알 수 있다','결론을 낼 수 있다','으로 인하여','있다','어떤것','관계가 있다','관련이 있다',\n",
    "'연관되다','어떤것들','에 대해','이리하여','그리하여','여부','하기보다는','하느니','하면 할수록','운운','이러이러하다','하구나','하도다','다시말하면','다음으로','에 있다',\n",
    "'에 달려 있다','우리','우리들','오히려','하기는한데','어떻게','어떻해','어찌됏어','어때','어째서','본대로','자','이','이쪽','여기','이것','이번','이렇게말하자면','이런','이러한',\n",
    "'이와 같은','요만큼','요만한 것','얼마 안 되는 것','이만큼','이 정도의','이렇게 많은 것','이와 같다','이때','이렇구나','것과 같이','끼익','삐걱,따위','와 같은 사람들',\n",
    "'부류의 사람들','왜냐하면','중의하나','오직','오로지','에 한하다','하기만 하면','도착하다','까지 미치다','도달하다','정도에 이르다','할 지경이다','결과에 이르다','관해서는',\n",
    "'여러분','하고 있다','한 후','혼자','자기','자기집','자신','우에' '종합한것과같이','총적으로' '보면','총적으로' '말하면','총적으로','대로 하다','으로서','참','그만이다','할 따름이다','쿵',\n",
    "'탕탕','쾅쾅','둥둥','봐','봐라','아이야','아니','와아','응','아이','참나','년','월','일','령','영','일','이','삼','사','오','육','륙','칠','팔','구','이천육','이천칠','이천팔','이천구','하나','둘','셋',\n",
    "'넷','다섯','여섯','일곱','여덟','아홉','령','영']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# konlpyList=['okt','']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1 #단어 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "okt=Okt()\n",
    "wordList=[]\n",
    "word_index={}\n",
    "wordCount={}\n",
    "train['okt']='0'\n",
    "for index ,sentencs in enumerate(train['comments']):\n",
    "    words=okt.morphs(sentencs,norm=True,stem=True)   \n",
    "    temp=[]\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            if len(word) >= n:\n",
    "                temp.append(word)\n",
    "                if word not in wordList:\n",
    "                    wordCount[word]=1\n",
    "                    wordList.append(word)\n",
    "                else:\n",
    "                    wordCount[word]=wordCount[word]+1\n",
    "    train['okt'].iloc[index]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount_df=pd.DataFrame([[i,j] for i,j in wordCount.items()],columns=['word', 'index'])\n",
    "wordCount_df.to_csv('wordCount_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=1 #빈도수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList=[]\n",
    "word_index={}\n",
    "for index ,word in enumerate(wordCount.keys()):\n",
    "    if wordCount[word]>= m : \n",
    "        word_index[word]=len(wordList)\n",
    "        wordList.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['okt']='0'\n",
    "for index ,sentencs in enumerate(test['comments']):\n",
    "    words=okt.morphs(sentencs,norm=True,stem=True)\n",
    "    temp=[]\n",
    "    for word in words:\n",
    "        if word in wordList:\n",
    "            temp.append(word)\n",
    "    test['okt'].iloc[index]=temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Term Matrix , One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dtm_array=[]\n",
    "train_ohe_array=[]\n",
    "for corpus in train['okt']:\n",
    "    temp1=[0]*len(word_index)\n",
    "    temp2=[0]*len(word_index)\n",
    "    for word in corpus:\n",
    "        if word in word_index.keys():\n",
    "            temp1[word_index[word]]=+1\n",
    "            temp2[word_index[word]]=1\n",
    "    train_dtm_array.append(temp1)\n",
    "    train_ohe_array.append(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dtm=pd.DataFrame(train_dtm_array,columns=word_index.keys())\n",
    "# train_dtm.to_csv('train_dtm.csv')\n",
    "train_ohe=pd.DataFrame(train_ohe_array,columns=word_index.keys())\n",
    "# train_ohe.to_csv('train_ohe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dtm_array=[]\n",
    "test_ohe_array=[]\n",
    "for corpus in test['okt']:\n",
    "    temp1=[0]*len(word_index)\n",
    "    temp2=[0]*len(word_index)\n",
    "    for word in corpus:\n",
    "        if word in word_index.keys():\n",
    "            temp1[word_index[word]]=+1\n",
    "            temp2[word_index[word]]=1\n",
    "    test_dtm_array.append(temp1)\n",
    "    test_ohe_array.append(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dtm=pd.DataFrame(test_dtm_array,columns=word_index.keys())\n",
    "# test_dtm.to_csv('test_dtm.csv')\n",
    "test_ohe=pd.DataFrame(test_ohe_array,columns=word_index.keys())\n",
    "# test_ohe.to_csv('test_ohe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xTrain yTrain xTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain=np.array(train_ohe_array)\n",
    "yTrain=train['label'].values\n",
    "xTest=np.array(test_ohe_array)\n",
    "yTest=test['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalNB()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=CategoricalNB()\n",
    "model.fit(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_NB=model.predict(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9187"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(xTrain , yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.893"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['pred_NB']=pred_NB\n",
    "(test['label']==test['pred_NB']).sum()/test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(dtm):\n",
    "    n=dtm.shape[0]\n",
    "    c=(dtm!=0).sum(axis=0)\n",
    "    m=np.log(n/(c+1))\n",
    "    return m*dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ifidf=tfidf(xTrain)\n",
    "test_ifidf=tfidf(xTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr(y_i, y):\n",
    "    p = train_dtm[y==y_i].sum(0)\n",
    "    return (p+1) / ((y==y_i).sum()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mdl(y):\n",
    "    y = y.values\n",
    "    r = np.log(pr(1,y) / pr(0,y))\n",
    "    m = LogisticRegression()\n",
    "    x_nb = train_dtm.multiply(r)\n",
    "    return m.fit(x_nb, y), r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,r = get_mdl(train['label'])\n",
    "preds=m.predict_proba(test_dtm.multiply(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.919"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_NB_SVM=[]\n",
    "for i in preds:\n",
    "    pred_NB_SVM.append(i.argmax())\n",
    "\n",
    "test['pred_NB_SVM']=pred_NB_SVM\n",
    "(test['label']==test['pred_NB_SVM']).sum()/test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(2048,input_shape=(xTrain.shape[1],) ,activation='relu'))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(2,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       ...,\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['none']=train['label']==0\n",
    "train['hate']=train['label']==1\n",
    "yTrain=train[['none','hate']].values\n",
    "yTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = xTrain[:2000]\n",
    "partial_x_train = xTrain[2000:]\n",
    "\n",
    "y_val = yTrain[:2000]\n",
    "partial_y_train = yTrain[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.6926 - accuracy: 0.5289 - val_loss: 0.6925 - val_accuracy: 0.5270\n",
      "Epoch 2/300\n",
      "36/36 [==============================] - 5s 137ms/step - loss: 0.6921 - accuracy: 0.5290 - val_loss: 0.6919 - val_accuracy: 0.5270\n",
      "Epoch 3/300\n",
      "36/36 [==============================] - 5s 137ms/step - loss: 0.6912 - accuracy: 0.5290 - val_loss: 0.6910 - val_accuracy: 0.5270\n",
      "Epoch 4/300\n",
      "36/36 [==============================] - 5s 140ms/step - loss: 0.6902 - accuracy: 0.5290 - val_loss: 0.6900 - val_accuracy: 0.5270\n",
      "Epoch 5/300\n",
      "36/36 [==============================] - 5s 138ms/step - loss: 0.6892 - accuracy: 0.5290 - val_loss: 0.6892 - val_accuracy: 0.5270\n",
      "Epoch 6/300\n",
      "36/36 [==============================] - 5s 137ms/step - loss: 0.6883 - accuracy: 0.5290 - val_loss: 0.6883 - val_accuracy: 0.5270\n",
      "Epoch 7/300\n",
      "36/36 [==============================] - 5s 138ms/step - loss: 0.6873 - accuracy: 0.5290 - val_loss: 0.6873 - val_accuracy: 0.5270\n",
      "Epoch 8/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.6862 - accuracy: 0.5290 - val_loss: 0.6863 - val_accuracy: 0.5270\n",
      "Epoch 9/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.6850 - accuracy: 0.5290 - val_loss: 0.6851 - val_accuracy: 0.5270\n",
      "Epoch 10/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.6836 - accuracy: 0.5290 - val_loss: 0.6838 - val_accuracy: 0.5270\n",
      "Epoch 11/300\n",
      "36/36 [==============================] - 5s 149ms/step - loss: 0.6821 - accuracy: 0.5290 - val_loss: 0.6823 - val_accuracy: 0.5270\n",
      "Epoch 12/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.6803 - accuracy: 0.5290 - val_loss: 0.6806 - val_accuracy: 0.5270\n",
      "Epoch 13/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.6784 - accuracy: 0.5291 - val_loss: 0.6786 - val_accuracy: 0.5270\n",
      "Epoch 14/300\n",
      "36/36 [==============================] - 5s 144ms/step - loss: 0.6762 - accuracy: 0.5291 - val_loss: 0.6765 - val_accuracy: 0.5270\n",
      "Epoch 15/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.6738 - accuracy: 0.5292 - val_loss: 0.6740 - val_accuracy: 0.5270\n",
      "Epoch 16/300\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.6710 - accuracy: 0.5298 - val_loss: 0.6713 - val_accuracy: 0.5275\n",
      "Epoch 17/300\n",
      "36/36 [==============================] - 5s 144ms/step - loss: 0.6679 - accuracy: 0.5318 - val_loss: 0.6682 - val_accuracy: 0.5305\n",
      "Epoch 18/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.6645 - accuracy: 0.5386 - val_loss: 0.6648 - val_accuracy: 0.5415\n",
      "Epoch 19/300\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.6607 - accuracy: 0.5524 - val_loss: 0.6610 - val_accuracy: 0.5575\n",
      "Epoch 20/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.6564 - accuracy: 0.5665 - val_loss: 0.6569 - val_accuracy: 0.5960\n",
      "Epoch 21/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.6518 - accuracy: 0.6043 - val_loss: 0.6522 - val_accuracy: 0.6160\n",
      "Epoch 22/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.6465 - accuracy: 0.6248 - val_loss: 0.6471 - val_accuracy: 0.6420\n",
      "Epoch 23/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.6407 - accuracy: 0.6571 - val_loss: 0.6414 - val_accuracy: 0.6730\n",
      "Epoch 24/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.6344 - accuracy: 0.6818 - val_loss: 0.6350 - val_accuracy: 0.6940\n",
      "Epoch 25/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.6274 - accuracy: 0.7041 - val_loss: 0.6281 - val_accuracy: 0.7230\n",
      "Epoch 26/300\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.6197 - accuracy: 0.7335 - val_loss: 0.6206 - val_accuracy: 0.7400\n",
      "Epoch 27/300\n",
      "36/36 [==============================] - 5s 144ms/step - loss: 0.6114 - accuracy: 0.7518 - val_loss: 0.6124 - val_accuracy: 0.7585\n",
      "Epoch 28/300\n",
      "36/36 [==============================] - 5s 145ms/step - loss: 0.6023 - accuracy: 0.7779 - val_loss: 0.6035 - val_accuracy: 0.7765\n",
      "Epoch 29/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.5925 - accuracy: 0.7960 - val_loss: 0.5940 - val_accuracy: 0.8010\n",
      "Epoch 30/300\n",
      "36/36 [==============================] - 5s 145ms/step - loss: 0.5821 - accuracy: 0.8170 - val_loss: 0.5838 - val_accuracy: 0.8170\n",
      "Epoch 31/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.5708 - accuracy: 0.8286 - val_loss: 0.5729 - val_accuracy: 0.8210\n",
      "Epoch 32/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.5590 - accuracy: 0.8347 - val_loss: 0.5615 - val_accuracy: 0.8220\n",
      "Epoch 33/300\n",
      "36/36 [==============================] - 5s 145ms/step - loss: 0.5467 - accuracy: 0.8379 - val_loss: 0.5497 - val_accuracy: 0.8315\n",
      "Epoch 34/300\n",
      "36/36 [==============================] - 5s 145ms/step - loss: 0.5340 - accuracy: 0.8414 - val_loss: 0.5377 - val_accuracy: 0.8245\n",
      "Epoch 35/300\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.5210 - accuracy: 0.8415 - val_loss: 0.5252 - val_accuracy: 0.8265\n",
      "Epoch 36/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.5077 - accuracy: 0.8426 - val_loss: 0.5126 - val_accuracy: 0.8285\n",
      "Epoch 37/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.4944 - accuracy: 0.8431 - val_loss: 0.5000 - val_accuracy: 0.8315\n",
      "Epoch 38/300\n",
      "36/36 [==============================] - 5s 149ms/step - loss: 0.4811 - accuracy: 0.8446 - val_loss: 0.4874 - val_accuracy: 0.8255\n",
      "Epoch 39/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.4679 - accuracy: 0.8449 - val_loss: 0.4749 - val_accuracy: 0.8290\n",
      "Epoch 40/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.4547 - accuracy: 0.8455 - val_loss: 0.4626 - val_accuracy: 0.8295\n",
      "Epoch 41/300\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.4418 - accuracy: 0.8464 - val_loss: 0.4505 - val_accuracy: 0.8360\n",
      "Epoch 42/300\n",
      "36/36 [==============================] - 5s 145ms/step - loss: 0.4291 - accuracy: 0.8495 - val_loss: 0.4386 - val_accuracy: 0.8390\n",
      "Epoch 43/300\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.4166 - accuracy: 0.8545 - val_loss: 0.4268 - val_accuracy: 0.8340\n",
      "Epoch 44/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.4044 - accuracy: 0.8547 - val_loss: 0.4154 - val_accuracy: 0.8390\n",
      "Epoch 45/300\n",
      "36/36 [==============================] - 5s 145ms/step - loss: 0.3926 - accuracy: 0.8576 - val_loss: 0.4044 - val_accuracy: 0.8420\n",
      "Epoch 46/300\n",
      "36/36 [==============================] - 5s 145ms/step - loss: 0.3811 - accuracy: 0.8613 - val_loss: 0.3936 - val_accuracy: 0.8455\n",
      "Epoch 47/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.3700 - accuracy: 0.8649 - val_loss: 0.3834 - val_accuracy: 0.8480\n",
      "Epoch 48/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.3592 - accuracy: 0.8697 - val_loss: 0.3744 - val_accuracy: 0.8430\n",
      "Epoch 49/300\n",
      "36/36 [==============================] - 5s 144ms/step - loss: 0.3491 - accuracy: 0.8708 - val_loss: 0.3644 - val_accuracy: 0.8515\n",
      "Epoch 50/300\n",
      "36/36 [==============================] - 5s 144ms/step - loss: 0.3391 - accuracy: 0.8760 - val_loss: 0.3556 - val_accuracy: 0.8545\n",
      "Epoch 51/300\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.3297 - accuracy: 0.8783 - val_loss: 0.3477 - val_accuracy: 0.8570\n",
      "Epoch 52/300\n",
      "36/36 [==============================] - 5s 145ms/step - loss: 0.3209 - accuracy: 0.8805 - val_loss: 0.3397 - val_accuracy: 0.8625\n",
      "Epoch 53/300\n",
      "36/36 [==============================] - 5s 145ms/step - loss: 0.3125 - accuracy: 0.8843 - val_loss: 0.3325 - val_accuracy: 0.8625\n",
      "Epoch 54/300\n",
      "36/36 [==============================] - 5s 144ms/step - loss: 0.3045 - accuracy: 0.8863 - val_loss: 0.3257 - val_accuracy: 0.8665\n",
      "Epoch 55/300\n",
      "36/36 [==============================] - 5s 145ms/step - loss: 0.2970 - accuracy: 0.8887 - val_loss: 0.3195 - val_accuracy: 0.8685\n",
      "Epoch 56/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.2898 - accuracy: 0.8911 - val_loss: 0.3149 - val_accuracy: 0.8680\n",
      "Epoch 57/300\n",
      "36/36 [==============================] - 5s 145ms/step - loss: 0.2832 - accuracy: 0.8922 - val_loss: 0.3082 - val_accuracy: 0.8715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/300\n",
      "36/36 [==============================] - 5s 145ms/step - loss: 0.2767 - accuracy: 0.8954 - val_loss: 0.3038 - val_accuracy: 0.8730\n",
      "Epoch 59/300\n",
      "36/36 [==============================] - 5s 144ms/step - loss: 0.2707 - accuracy: 0.8960 - val_loss: 0.2982 - val_accuracy: 0.8755\n",
      "Epoch 60/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.2650 - accuracy: 0.8989 - val_loss: 0.2938 - val_accuracy: 0.8780\n",
      "Epoch 61/300\n",
      "36/36 [==============================] - 5s 145ms/step - loss: 0.2594 - accuracy: 0.9024 - val_loss: 0.2904 - val_accuracy: 0.8770\n",
      "Epoch 62/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.2544 - accuracy: 0.9021 - val_loss: 0.2859 - val_accuracy: 0.8815\n",
      "Epoch 63/300\n",
      "36/36 [==============================] - 5s 144ms/step - loss: 0.2494 - accuracy: 0.9049 - val_loss: 0.2834 - val_accuracy: 0.8855\n",
      "Epoch 64/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.2449 - accuracy: 0.9077 - val_loss: 0.2796 - val_accuracy: 0.8820\n",
      "Epoch 65/300\n",
      "36/36 [==============================] - 5s 144ms/step - loss: 0.2403 - accuracy: 0.9072 - val_loss: 0.2774 - val_accuracy: 0.8795\n",
      "Epoch 66/300\n",
      "36/36 [==============================] - 5s 144ms/step - loss: 0.2360 - accuracy: 0.9090 - val_loss: 0.2732 - val_accuracy: 0.8850\n",
      "Epoch 67/300\n",
      "36/36 [==============================] - 5s 144ms/step - loss: 0.2319 - accuracy: 0.9106 - val_loss: 0.2702 - val_accuracy: 0.8880\n",
      "Epoch 68/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.2279 - accuracy: 0.9129 - val_loss: 0.2684 - val_accuracy: 0.8865\n",
      "Epoch 69/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.2240 - accuracy: 0.9134 - val_loss: 0.2671 - val_accuracy: 0.8840\n",
      "Epoch 70/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.2204 - accuracy: 0.9143 - val_loss: 0.2639 - val_accuracy: 0.8895\n",
      "Epoch 71/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.2168 - accuracy: 0.9170 - val_loss: 0.2623 - val_accuracy: 0.8905\n",
      "Epoch 72/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.2134 - accuracy: 0.9175 - val_loss: 0.2588 - val_accuracy: 0.8940\n",
      "Epoch 73/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.2100 - accuracy: 0.9189 - val_loss: 0.2572 - val_accuracy: 0.8925\n",
      "Epoch 74/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.2067 - accuracy: 0.9202 - val_loss: 0.2547 - val_accuracy: 0.8955\n",
      "Epoch 75/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.2038 - accuracy: 0.9216 - val_loss: 0.2535 - val_accuracy: 0.8965\n",
      "Epoch 76/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.2005 - accuracy: 0.9227 - val_loss: 0.2558 - val_accuracy: 0.8885\n",
      "Epoch 77/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1979 - accuracy: 0.9232 - val_loss: 0.2501 - val_accuracy: 0.8985\n",
      "Epoch 78/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1946 - accuracy: 0.9253 - val_loss: 0.2490 - val_accuracy: 0.9000\n",
      "Epoch 79/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1918 - accuracy: 0.9268 - val_loss: 0.2522 - val_accuracy: 0.8940\n",
      "Epoch 80/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1891 - accuracy: 0.9278 - val_loss: 0.2469 - val_accuracy: 0.9005\n",
      "Epoch 81/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1863 - accuracy: 0.9282 - val_loss: 0.2445 - val_accuracy: 0.8975\n",
      "Epoch 82/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1834 - accuracy: 0.9299 - val_loss: 0.2519 - val_accuracy: 0.8930\n",
      "Epoch 83/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.1811 - accuracy: 0.9299 - val_loss: 0.2418 - val_accuracy: 0.9000\n",
      "Epoch 84/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1783 - accuracy: 0.9322 - val_loss: 0.2419 - val_accuracy: 0.9000\n",
      "Epoch 85/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1758 - accuracy: 0.9331 - val_loss: 0.2394 - val_accuracy: 0.9010\n",
      "Epoch 86/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1733 - accuracy: 0.9338 - val_loss: 0.2403 - val_accuracy: 0.9020\n",
      "Epoch 87/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1707 - accuracy: 0.9348 - val_loss: 0.2374 - val_accuracy: 0.9010\n",
      "Epoch 88/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.1683 - accuracy: 0.9364 - val_loss: 0.2367 - val_accuracy: 0.9035\n",
      "Epoch 89/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1660 - accuracy: 0.9376 - val_loss: 0.2354 - val_accuracy: 0.9030\n",
      "Epoch 90/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1637 - accuracy: 0.9391 - val_loss: 0.2346 - val_accuracy: 0.9040\n",
      "Epoch 91/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1613 - accuracy: 0.9403 - val_loss: 0.2408 - val_accuracy: 0.9020\n",
      "Epoch 92/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1592 - accuracy: 0.9409 - val_loss: 0.2342 - val_accuracy: 0.9040\n",
      "Epoch 93/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1570 - accuracy: 0.9418 - val_loss: 0.2320 - val_accuracy: 0.9060\n",
      "Epoch 94/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.1546 - accuracy: 0.9431 - val_loss: 0.2314 - val_accuracy: 0.9055\n",
      "Epoch 95/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1523 - accuracy: 0.9447 - val_loss: 0.2311 - val_accuracy: 0.9065\n",
      "Epoch 96/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1502 - accuracy: 0.9459 - val_loss: 0.2305 - val_accuracy: 0.9075\n",
      "Epoch 97/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1480 - accuracy: 0.9462 - val_loss: 0.2405 - val_accuracy: 0.9015\n",
      "Epoch 98/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.1463 - accuracy: 0.9467 - val_loss: 0.2304 - val_accuracy: 0.9075\n",
      "Epoch 99/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1441 - accuracy: 0.9481 - val_loss: 0.2307 - val_accuracy: 0.9045\n",
      "Epoch 100/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1419 - accuracy: 0.9487 - val_loss: 0.2327 - val_accuracy: 0.9060\n",
      "Epoch 101/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1400 - accuracy: 0.9499 - val_loss: 0.2294 - val_accuracy: 0.9065\n",
      "Epoch 102/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1379 - accuracy: 0.9513 - val_loss: 0.2275 - val_accuracy: 0.9080\n",
      "Epoch 103/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1359 - accuracy: 0.9522 - val_loss: 0.2281 - val_accuracy: 0.9065\n",
      "Epoch 104/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1338 - accuracy: 0.9526 - val_loss: 0.2287 - val_accuracy: 0.9065\n",
      "Epoch 105/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.1321 - accuracy: 0.9532 - val_loss: 0.2273 - val_accuracy: 0.9080\n",
      "Epoch 106/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1302 - accuracy: 0.9546 - val_loss: 0.2265 - val_accuracy: 0.9080\n",
      "Epoch 107/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1283 - accuracy: 0.9556 - val_loss: 0.2272 - val_accuracy: 0.9080\n",
      "Epoch 108/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1264 - accuracy: 0.9561 - val_loss: 0.2273 - val_accuracy: 0.9070\n",
      "Epoch 109/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1246 - accuracy: 0.9572 - val_loss: 0.2257 - val_accuracy: 0.9090\n",
      "Epoch 110/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1229 - accuracy: 0.9578 - val_loss: 0.2276 - val_accuracy: 0.9080\n",
      "Epoch 111/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1210 - accuracy: 0.9590 - val_loss: 0.2262 - val_accuracy: 0.9070\n",
      "Epoch 112/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1194 - accuracy: 0.9594 - val_loss: 0.2256 - val_accuracy: 0.9080\n",
      "Epoch 113/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1175 - accuracy: 0.9608 - val_loss: 0.2265 - val_accuracy: 0.9100\n",
      "Epoch 114/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1158 - accuracy: 0.9613 - val_loss: 0.2256 - val_accuracy: 0.9080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1142 - accuracy: 0.9620 - val_loss: 0.2284 - val_accuracy: 0.9075\n",
      "Epoch 116/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1126 - accuracy: 0.9626 - val_loss: 0.2250 - val_accuracy: 0.9095\n",
      "Epoch 117/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1109 - accuracy: 0.9640 - val_loss: 0.2271 - val_accuracy: 0.9085\n",
      "Epoch 118/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1092 - accuracy: 0.9648 - val_loss: 0.2264 - val_accuracy: 0.9080\n",
      "Epoch 119/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1076 - accuracy: 0.9649 - val_loss: 0.2253 - val_accuracy: 0.9105\n",
      "Epoch 120/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1059 - accuracy: 0.9661 - val_loss: 0.2257 - val_accuracy: 0.9070\n",
      "Epoch 121/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1046 - accuracy: 0.9667 - val_loss: 0.2339 - val_accuracy: 0.9050\n",
      "Epoch 122/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1031 - accuracy: 0.9674 - val_loss: 0.2272 - val_accuracy: 0.9095\n",
      "Epoch 123/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.1013 - accuracy: 0.9681 - val_loss: 0.2299 - val_accuracy: 0.9070\n",
      "Epoch 124/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.0998 - accuracy: 0.9680 - val_loss: 0.2452 - val_accuracy: 0.9030\n",
      "Epoch 125/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.0990 - accuracy: 0.9687 - val_loss: 0.2267 - val_accuracy: 0.9100\n",
      "Epoch 126/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.0970 - accuracy: 0.9695 - val_loss: 0.2306 - val_accuracy: 0.9075\n",
      "Epoch 127/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.0955 - accuracy: 0.9701 - val_loss: 0.2271 - val_accuracy: 0.9090\n",
      "Epoch 128/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.0941 - accuracy: 0.9709 - val_loss: 0.2278 - val_accuracy: 0.9115\n",
      "Epoch 129/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.0925 - accuracy: 0.9723 - val_loss: 0.2289 - val_accuracy: 0.9100\n",
      "Epoch 130/300\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.0913 - accuracy: 0.9719 - val_loss: 0.2285 - val_accuracy: 0.9115\n",
      "Epoch 131/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.0900 - accuracy: 0.9726 - val_loss: 0.2307 - val_accuracy: 0.9055\n",
      "Epoch 132/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.0886 - accuracy: 0.9727 - val_loss: 0.2292 - val_accuracy: 0.9105\n",
      "Epoch 133/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.0871 - accuracy: 0.9744 - val_loss: 0.2309 - val_accuracy: 0.9085\n",
      "Epoch 134/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.0858 - accuracy: 0.9739 - val_loss: 0.2297 - val_accuracy: 0.9085\n",
      "Epoch 135/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.0847 - accuracy: 0.9748 - val_loss: 0.2309 - val_accuracy: 0.9095\n",
      "Epoch 136/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.0833 - accuracy: 0.9751 - val_loss: 0.2312 - val_accuracy: 0.9100\n",
      "Epoch 137/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.0823 - accuracy: 0.9754 - val_loss: 0.2341 - val_accuracy: 0.9040\n",
      "Epoch 138/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.0810 - accuracy: 0.9760 - val_loss: 0.2331 - val_accuracy: 0.9040\n",
      "Epoch 139/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.0798 - accuracy: 0.9766 - val_loss: 0.2385 - val_accuracy: 0.9100\n",
      "Epoch 140/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.0785 - accuracy: 0.9773 - val_loss: 0.2329 - val_accuracy: 0.9090\n",
      "Epoch 141/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.0773 - accuracy: 0.9780 - val_loss: 0.2331 - val_accuracy: 0.9100\n",
      "Epoch 142/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.0761 - accuracy: 0.9781 - val_loss: 0.2337 - val_accuracy: 0.9090\n",
      "Epoch 143/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.0752 - accuracy: 0.9784 - val_loss: 0.2344 - val_accuracy: 0.9075\n",
      "Epoch 144/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.0740 - accuracy: 0.9791 - val_loss: 0.2351 - val_accuracy: 0.9075\n",
      "Epoch 145/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.0727 - accuracy: 0.9793 - val_loss: 0.2389 - val_accuracy: 0.9095\n",
      "Epoch 146/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.0720 - accuracy: 0.9796 - val_loss: 0.2362 - val_accuracy: 0.9075\n",
      "Epoch 147/300\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.0708 - accuracy: 0.9798 - val_loss: 0.2367 - val_accuracy: 0.9075\n",
      "Epoch 148/300\n",
      "36/36 [==============================] - 5s 144ms/step - loss: 0.0696 - accuracy: 0.9808 - val_loss: 0.2379 - val_accuracy: 0.9090\n",
      "Epoch 149/300\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.0686 - accuracy: 0.9810 - val_loss: 0.2378 - val_accuracy: 0.9070\n",
      "Epoch 150/300\n",
      "36/36 [==============================] - 5s 149ms/step - loss: 0.0676 - accuracy: 0.9817 - val_loss: 0.2396 - val_accuracy: 0.9070\n",
      "Epoch 151/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0667 - accuracy: 0.9814 - val_loss: 0.2421 - val_accuracy: 0.9095\n",
      "Epoch 152/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0659 - accuracy: 0.9817 - val_loss: 0.2402 - val_accuracy: 0.9055\n",
      "Epoch 153/300\n",
      "36/36 [==============================] - 5s 150ms/step - loss: 0.0649 - accuracy: 0.9821 - val_loss: 0.2409 - val_accuracy: 0.9065\n",
      "Epoch 154/300\n",
      "36/36 [==============================] - 5s 149ms/step - loss: 0.0642 - accuracy: 0.9823 - val_loss: 0.2412 - val_accuracy: 0.9070\n",
      "Epoch 155/300\n",
      "36/36 [==============================] - 5s 149ms/step - loss: 0.0629 - accuracy: 0.9834 - val_loss: 0.2423 - val_accuracy: 0.9075\n",
      "Epoch 156/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0620 - accuracy: 0.9832 - val_loss: 0.2426 - val_accuracy: 0.9070\n",
      "Epoch 157/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0611 - accuracy: 0.9829 - val_loss: 0.2447 - val_accuracy: 0.9085\n",
      "Epoch 158/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0604 - accuracy: 0.9838 - val_loss: 0.2441 - val_accuracy: 0.9065\n",
      "Epoch 159/300\n",
      "36/36 [==============================] - 5s 149ms/step - loss: 0.0598 - accuracy: 0.9834 - val_loss: 0.2453 - val_accuracy: 0.9070\n",
      "Epoch 160/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0587 - accuracy: 0.9839 - val_loss: 0.2458 - val_accuracy: 0.9065\n",
      "Epoch 161/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0578 - accuracy: 0.9839 - val_loss: 0.2475 - val_accuracy: 0.9085\n",
      "Epoch 162/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0571 - accuracy: 0.9849 - val_loss: 0.2504 - val_accuracy: 0.9040\n",
      "Epoch 163/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0565 - accuracy: 0.9849 - val_loss: 0.2507 - val_accuracy: 0.9080\n",
      "Epoch 164/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0556 - accuracy: 0.9847 - val_loss: 0.2556 - val_accuracy: 0.9100\n",
      "Epoch 165/300\n",
      "36/36 [==============================] - 5s 149ms/step - loss: 0.0548 - accuracy: 0.9853 - val_loss: 0.2506 - val_accuracy: 0.9080\n",
      "Epoch 166/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0539 - accuracy: 0.9852 - val_loss: 0.2504 - val_accuracy: 0.9045\n",
      "Epoch 167/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0533 - accuracy: 0.9853 - val_loss: 0.2504 - val_accuracy: 0.9035\n",
      "Epoch 168/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0527 - accuracy: 0.9854 - val_loss: 0.2574 - val_accuracy: 0.9090\n",
      "Epoch 169/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0522 - accuracy: 0.9859 - val_loss: 0.2580 - val_accuracy: 0.9095\n",
      "Epoch 170/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0513 - accuracy: 0.9858 - val_loss: 0.2536 - val_accuracy: 0.9070\n",
      "Epoch 171/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 5s 149ms/step - loss: 0.0506 - accuracy: 0.9863 - val_loss: 0.2573 - val_accuracy: 0.9095\n",
      "Epoch 172/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0501 - accuracy: 0.9862 - val_loss: 0.2554 - val_accuracy: 0.9075\n",
      "Epoch 173/300\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.0494 - accuracy: 0.9864 - val_loss: 0.2579 - val_accuracy: 0.9025\n",
      "Epoch 174/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0488 - accuracy: 0.9864 - val_loss: 0.2618 - val_accuracy: 0.9090\n",
      "Epoch 175/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0482 - accuracy: 0.9867 - val_loss: 0.2573 - val_accuracy: 0.9050\n",
      "Epoch 176/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0477 - accuracy: 0.9866 - val_loss: 0.2587 - val_accuracy: 0.9025\n",
      "Epoch 177/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0469 - accuracy: 0.9869 - val_loss: 0.2592 - val_accuracy: 0.9015\n",
      "Epoch 178/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0463 - accuracy: 0.9874 - val_loss: 0.2604 - val_accuracy: 0.9090\n",
      "Epoch 179/300\n",
      "36/36 [==============================] - 5s 149ms/step - loss: 0.0456 - accuracy: 0.9872 - val_loss: 0.2597 - val_accuracy: 0.9050\n",
      "Epoch 180/300\n",
      "36/36 [==============================] - 5s 149ms/step - loss: 0.0450 - accuracy: 0.9876 - val_loss: 0.2609 - val_accuracy: 0.9045\n",
      "Epoch 181/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0447 - accuracy: 0.9877 - val_loss: 0.2611 - val_accuracy: 0.9055\n",
      "Epoch 182/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0441 - accuracy: 0.9876 - val_loss: 0.2626 - val_accuracy: 0.9080\n",
      "Epoch 183/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0434 - accuracy: 0.9874 - val_loss: 0.2694 - val_accuracy: 0.9085\n",
      "Epoch 184/300\n",
      "36/36 [==============================] - 5s 149ms/step - loss: 0.0430 - accuracy: 0.9882 - val_loss: 0.2667 - val_accuracy: 0.8990\n",
      "Epoch 185/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0426 - accuracy: 0.9876 - val_loss: 0.2646 - val_accuracy: 0.9045\n",
      "Epoch 186/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0419 - accuracy: 0.9881 - val_loss: 0.2699 - val_accuracy: 0.9090\n",
      "Epoch 187/300\n",
      "36/36 [==============================] - 5s 149ms/step - loss: 0.0412 - accuracy: 0.9882 - val_loss: 0.2687 - val_accuracy: 0.9105\n",
      "Epoch 188/300\n",
      "36/36 [==============================] - 5s 150ms/step - loss: 0.0407 - accuracy: 0.9885 - val_loss: 0.2679 - val_accuracy: 0.9085\n",
      "Epoch 189/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0403 - accuracy: 0.9883 - val_loss: 0.2680 - val_accuracy: 0.9085\n",
      "Epoch 190/300\n",
      "36/36 [==============================] - 5s 149ms/step - loss: 0.0399 - accuracy: 0.9883 - val_loss: 0.2689 - val_accuracy: 0.9045\n",
      "Epoch 191/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0393 - accuracy: 0.9891 - val_loss: 0.2716 - val_accuracy: 0.9095\n",
      "Epoch 192/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0390 - accuracy: 0.9883 - val_loss: 0.2701 - val_accuracy: 0.9085\n",
      "Epoch 193/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0385 - accuracy: 0.9884 - val_loss: 0.2716 - val_accuracy: 0.9080\n",
      "Epoch 194/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0378 - accuracy: 0.9887 - val_loss: 0.2743 - val_accuracy: 0.9090\n",
      "Epoch 195/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0374 - accuracy: 0.9890 - val_loss: 0.2739 - val_accuracy: 0.9085\n",
      "Epoch 196/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0372 - accuracy: 0.9884 - val_loss: 0.2720 - val_accuracy: 0.9065\n",
      "Epoch 197/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0367 - accuracy: 0.9890 - val_loss: 0.2764 - val_accuracy: 0.9085\n",
      "Epoch 198/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0362 - accuracy: 0.9894 - val_loss: 0.2819 - val_accuracy: 0.9065\n",
      "Epoch 199/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0364 - accuracy: 0.9888 - val_loss: 0.2752 - val_accuracy: 0.9040\n",
      "Epoch 200/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0357 - accuracy: 0.9889 - val_loss: 0.2796 - val_accuracy: 0.9085\n",
      "Epoch 201/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0353 - accuracy: 0.9890 - val_loss: 0.2798 - val_accuracy: 0.9005\n",
      "Epoch 202/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0351 - accuracy: 0.9893 - val_loss: 0.2776 - val_accuracy: 0.9055\n",
      "Epoch 203/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0346 - accuracy: 0.9891 - val_loss: 0.2779 - val_accuracy: 0.9060\n",
      "Epoch 204/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0339 - accuracy: 0.9898 - val_loss: 0.2945 - val_accuracy: 0.9065\n",
      "Epoch 205/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0339 - accuracy: 0.9897 - val_loss: 0.2801 - val_accuracy: 0.9070\n",
      "Epoch 206/300\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.0334 - accuracy: 0.9896 - val_loss: 0.2821 - val_accuracy: 0.9015\n",
      "Epoch 207/300\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.0333 - accuracy: 0.9896 - val_loss: 0.2814 - val_accuracy: 0.9070\n",
      "Epoch 208/300\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.0327 - accuracy: 0.9896 - val_loss: 0.2815 - val_accuracy: 0.9075\n",
      "Epoch 209/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0326 - accuracy: 0.9894 - val_loss: 0.2828 - val_accuracy: 0.9075\n",
      "Epoch 210/300\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.0322 - accuracy: 0.9895 - val_loss: 0.3038 - val_accuracy: 0.9065\n",
      "Epoch 211/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0320 - accuracy: 0.9898 - val_loss: 0.2877 - val_accuracy: 0.9085\n",
      "Epoch 212/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0316 - accuracy: 0.9897 - val_loss: 0.2980 - val_accuracy: 0.9065\n",
      "Epoch 213/300\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.0314 - accuracy: 0.9897 - val_loss: 0.2960 - val_accuracy: 0.9060\n",
      "Epoch 214/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0311 - accuracy: 0.9898 - val_loss: 0.2869 - val_accuracy: 0.9065\n",
      "Epoch 215/300\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.0309 - accuracy: 0.9901 - val_loss: 0.2900 - val_accuracy: 0.9080\n",
      "Epoch 216/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0306 - accuracy: 0.9902 - val_loss: 0.2933 - val_accuracy: 0.9055\n",
      "Epoch 217/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0302 - accuracy: 0.9897 - val_loss: 0.2890 - val_accuracy: 0.9075\n",
      "Epoch 218/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0300 - accuracy: 0.9898 - val_loss: 0.2900 - val_accuracy: 0.9055\n",
      "Epoch 219/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0297 - accuracy: 0.9904 - val_loss: 0.3147 - val_accuracy: 0.9040\n",
      "Epoch 220/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0294 - accuracy: 0.9901 - val_loss: 0.2915 - val_accuracy: 0.9050\n",
      "Epoch 221/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0293 - accuracy: 0.9907 - val_loss: 0.2979 - val_accuracy: 0.9055\n",
      "Epoch 222/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0290 - accuracy: 0.9900 - val_loss: 0.2932 - val_accuracy: 0.9055\n",
      "Epoch 223/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0286 - accuracy: 0.9906 - val_loss: 0.2974 - val_accuracy: 0.9005\n",
      "Epoch 224/300\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.0287 - accuracy: 0.9898 - val_loss: 0.3006 - val_accuracy: 0.8950\n",
      "Epoch 225/300\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.0285 - accuracy: 0.9899 - val_loss: 0.2991 - val_accuracy: 0.9055\n",
      "Epoch 226/300\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.0280 - accuracy: 0.9909 - val_loss: 0.3104 - val_accuracy: 0.9055\n",
      "Epoch 227/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 5s 146ms/step - loss: 0.0279 - accuracy: 0.9903 - val_loss: 0.2984 - val_accuracy: 0.9025\n",
      "Epoch 228/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0277 - accuracy: 0.9901 - val_loss: 0.3012 - val_accuracy: 0.9060\n",
      "Epoch 229/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0273 - accuracy: 0.9906 - val_loss: 0.2983 - val_accuracy: 0.9090\n",
      "Epoch 230/300\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.0273 - accuracy: 0.9899 - val_loss: 0.3002 - val_accuracy: 0.9075\n",
      "Epoch 231/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0268 - accuracy: 0.9908 - val_loss: 0.2988 - val_accuracy: 0.9070\n",
      "Epoch 232/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0267 - accuracy: 0.9903 - val_loss: 0.3004 - val_accuracy: 0.9055\n",
      "Epoch 233/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0267 - accuracy: 0.9904 - val_loss: 0.3032 - val_accuracy: 0.9070\n",
      "Epoch 234/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0265 - accuracy: 0.9908 - val_loss: 0.3027 - val_accuracy: 0.9065\n",
      "Epoch 235/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0263 - accuracy: 0.9905 - val_loss: 0.3025 - val_accuracy: 0.9055\n",
      "Epoch 236/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0261 - accuracy: 0.9901 - val_loss: 0.3053 - val_accuracy: 0.9060\n",
      "Epoch 237/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0259 - accuracy: 0.9903 - val_loss: 0.3046 - val_accuracy: 0.9070\n",
      "Epoch 238/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0258 - accuracy: 0.9905 - val_loss: 0.3045 - val_accuracy: 0.9070\n",
      "Epoch 239/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0255 - accuracy: 0.9904 - val_loss: 0.3113 - val_accuracy: 0.9035\n",
      "Epoch 240/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0254 - accuracy: 0.9906 - val_loss: 0.3055 - val_accuracy: 0.9065\n",
      "Epoch 241/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0255 - accuracy: 0.9900 - val_loss: 0.3072 - val_accuracy: 0.9040\n",
      "Epoch 242/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0251 - accuracy: 0.9909 - val_loss: 0.3166 - val_accuracy: 0.9060\n",
      "Epoch 243/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0251 - accuracy: 0.9907 - val_loss: 0.3161 - val_accuracy: 0.9040\n",
      "Epoch 244/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0247 - accuracy: 0.9909 - val_loss: 0.3111 - val_accuracy: 0.9060\n",
      "Epoch 245/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0247 - accuracy: 0.9908 - val_loss: 0.3174 - val_accuracy: 0.9045\n",
      "Epoch 246/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0245 - accuracy: 0.9915 - val_loss: 0.3105 - val_accuracy: 0.9055\n",
      "Epoch 247/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0244 - accuracy: 0.9911 - val_loss: 0.3112 - val_accuracy: 0.9055\n",
      "Epoch 248/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0243 - accuracy: 0.9910 - val_loss: 0.3126 - val_accuracy: 0.9030\n",
      "Epoch 249/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0241 - accuracy: 0.9908 - val_loss: 0.3144 - val_accuracy: 0.9065\n",
      "Epoch 250/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0238 - accuracy: 0.9909 - val_loss: 0.3144 - val_accuracy: 0.9050\n",
      "Epoch 251/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0239 - accuracy: 0.9918 - val_loss: 0.3177 - val_accuracy: 0.9055\n",
      "Epoch 252/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0237 - accuracy: 0.9907 - val_loss: 0.3243 - val_accuracy: 0.9040\n",
      "Epoch 253/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0235 - accuracy: 0.9911 - val_loss: 0.3175 - val_accuracy: 0.9065\n",
      "Epoch 254/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0234 - accuracy: 0.9908 - val_loss: 0.3168 - val_accuracy: 0.9055\n",
      "Epoch 255/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0231 - accuracy: 0.9914 - val_loss: 0.3165 - val_accuracy: 0.9050\n",
      "Epoch 256/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0231 - accuracy: 0.9911 - val_loss: 0.3161 - val_accuracy: 0.9055\n",
      "Epoch 257/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0228 - accuracy: 0.9917 - val_loss: 0.3180 - val_accuracy: 0.9050\n",
      "Epoch 258/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0230 - accuracy: 0.9912 - val_loss: 0.3185 - val_accuracy: 0.9045\n",
      "Epoch 259/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0227 - accuracy: 0.9911 - val_loss: 0.3245 - val_accuracy: 0.9045\n",
      "Epoch 260/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0226 - accuracy: 0.9912 - val_loss: 0.3294 - val_accuracy: 0.9050\n",
      "Epoch 261/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0225 - accuracy: 0.9916 - val_loss: 0.3260 - val_accuracy: 0.9050\n",
      "Epoch 262/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0222 - accuracy: 0.9916 - val_loss: 0.3226 - val_accuracy: 0.9030\n",
      "Epoch 263/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0222 - accuracy: 0.9921 - val_loss: 0.3212 - val_accuracy: 0.9065\n",
      "Epoch 264/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0221 - accuracy: 0.9908 - val_loss: 0.3224 - val_accuracy: 0.9060\n",
      "Epoch 265/300\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.0219 - accuracy: 0.9918 - val_loss: 0.3219 - val_accuracy: 0.9040\n",
      "Epoch 266/300\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.0218 - accuracy: 0.9909 - val_loss: 0.3251 - val_accuracy: 0.9065\n",
      "Epoch 267/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0217 - accuracy: 0.9914 - val_loss: 0.3236 - val_accuracy: 0.9055\n",
      "Epoch 268/300\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.0216 - accuracy: 0.9914 - val_loss: 0.3254 - val_accuracy: 0.9055\n",
      "Epoch 269/300\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.0215 - accuracy: 0.9913 - val_loss: 0.3244 - val_accuracy: 0.9040\n",
      "Epoch 270/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0215 - accuracy: 0.9914 - val_loss: 0.3253 - val_accuracy: 0.9060\n",
      "Epoch 271/300\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.0215 - accuracy: 0.9912 - val_loss: 0.3253 - val_accuracy: 0.9045\n",
      "Epoch 272/300\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.0214 - accuracy: 0.9919 - val_loss: 0.3257 - val_accuracy: 0.9050\n",
      "Epoch 273/300\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.0215 - accuracy: 0.9909 - val_loss: 0.3267 - val_accuracy: 0.9055\n",
      "Epoch 274/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0211 - accuracy: 0.9917 - val_loss: 0.3314 - val_accuracy: 0.9045\n",
      "Epoch 275/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0211 - accuracy: 0.9912 - val_loss: 0.3279 - val_accuracy: 0.9075\n",
      "Epoch 276/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0210 - accuracy: 0.9919 - val_loss: 0.3378 - val_accuracy: 0.9065\n",
      "Epoch 277/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0209 - accuracy: 0.9913 - val_loss: 0.3294 - val_accuracy: 0.9065\n",
      "Epoch 278/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0208 - accuracy: 0.9923 - val_loss: 0.3381 - val_accuracy: 0.9065\n",
      "Epoch 279/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0207 - accuracy: 0.9918 - val_loss: 0.3479 - val_accuracy: 0.9035\n",
      "Epoch 280/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0208 - accuracy: 0.9921 - val_loss: 0.3371 - val_accuracy: 0.9040\n",
      "Epoch 281/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0207 - accuracy: 0.9918 - val_loss: 0.3565 - val_accuracy: 0.9025\n",
      "Epoch 282/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0204 - accuracy: 0.9921 - val_loss: 0.3472 - val_accuracy: 0.9045\n",
      "Epoch 283/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0206 - accuracy: 0.9914 - val_loss: 0.3333 - val_accuracy: 0.9035\n",
      "Epoch 284/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0202 - accuracy: 0.9914 - val_loss: 0.3517 - val_accuracy: 0.9045\n",
      "Epoch 285/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0204 - accuracy: 0.9914 - val_loss: 0.3446 - val_accuracy: 0.9050\n",
      "Epoch 286/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0202 - accuracy: 0.9918 - val_loss: 0.3362 - val_accuracy: 0.9060\n",
      "Epoch 287/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0200 - accuracy: 0.9924 - val_loss: 0.3348 - val_accuracy: 0.9050\n",
      "Epoch 288/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0200 - accuracy: 0.9915 - val_loss: 0.3362 - val_accuracy: 0.9045\n",
      "Epoch 289/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0198 - accuracy: 0.9932 - val_loss: 0.3360 - val_accuracy: 0.9065\n",
      "Epoch 290/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0199 - accuracy: 0.9917 - val_loss: 0.3374 - val_accuracy: 0.9035\n",
      "Epoch 291/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0195 - accuracy: 0.9927 - val_loss: 0.3421 - val_accuracy: 0.9060\n",
      "Epoch 292/300\n",
      "36/36 [==============================] - 5s 149ms/step - loss: 0.0196 - accuracy: 0.9919 - val_loss: 0.3479 - val_accuracy: 0.9060\n",
      "Epoch 293/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0197 - accuracy: 0.9919 - val_loss: 0.3446 - val_accuracy: 0.9050\n",
      "Epoch 294/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0196 - accuracy: 0.9918 - val_loss: 0.3387 - val_accuracy: 0.9055\n",
      "Epoch 295/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0194 - accuracy: 0.9921 - val_loss: 0.3470 - val_accuracy: 0.9060\n",
      "Epoch 296/300\n",
      "36/36 [==============================] - 5s 149ms/step - loss: 0.0194 - accuracy: 0.9918 - val_loss: 0.3395 - val_accuracy: 0.9035\n",
      "Epoch 297/300\n",
      "36/36 [==============================] - 5s 147ms/step - loss: 0.0193 - accuracy: 0.9919 - val_loss: 0.3441 - val_accuracy: 0.9060\n",
      "Epoch 298/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0193 - accuracy: 0.9913 - val_loss: 0.3411 - val_accuracy: 0.9060\n",
      "Epoch 299/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0192 - accuracy: 0.9917 - val_loss: 0.3429 - val_accuracy: 0.9050\n",
      "Epoch 300/300\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0192 - accuracy: 0.9918 - val_loss: 0.3427 - val_accuracy: 0.9025\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=300,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss= history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo',label=\"Training loss\" )\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf() #그래프 초기화 \n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('RNN_model_small.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_RNN=model.predict(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_RNN_list=[]\n",
    "for i in range(len(pred_RNN)):\n",
    "    pred_RNN_list.append(pred_RNN[i].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90625"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['pred_RNN']=pred_RNN_list\n",
    "(test['label']==test['pred_RNN']).sum()/test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
