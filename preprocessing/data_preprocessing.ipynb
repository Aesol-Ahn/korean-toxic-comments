{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from konlpy.tag import Okt, Mecab\n",
    "from khaiii import KhaiiiAPi\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>정말 재밌다 연기도 좋고 디카프리오 짱</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>심쿵심쿵 미치네요이수혁땜에 잠 못자겠어요ㅠ자꾸 아른거림ㅠ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>하지만 이니후빨러들은 이런거 관심 하나도 없음</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@착한아이임당 A4 용지 덮고?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>진짜 평점 믿으면 안된 다는 걸 현실로 보여주는 영화입니다. 네티즌,전문가 하나같이...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  label\n",
       "0                              정말 재밌다 연기도 좋고 디카프리오 짱      1\n",
       "1                    심쿵심쿵 미치네요이수혁땜에 잠 못자겠어요ㅠ자꾸 아른거림ㅠ      1\n",
       "2                          하지만 이니후빨러들은 이런거 관심 하나도 없음      0\n",
       "3                                  @착한아이임당 A4 용지 덮고?      0\n",
       "4  진짜 평점 믿으면 안된 다는 걸 현실로 보여주는 영화입니다. 네티즌,전문가 하나같이...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/hate_speech_large.csv')\n",
    "data.columns = ['comments', 'label']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "댓글 개수 : 190000\n"
     ]
    }
   ],
   "source": [
    "print(\"댓글 개수 :\",len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 정제\n",
    "* 긍정 댓글: 0\n",
    "* 악성 댓글: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = np.where(data['label'] == 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "컬럼 별 고유 샘플의 수 : (187142, 2)\n",
      "중복 제거 후 총 샘플의 수 : 187143\n"
     ]
    }
   ],
   "source": [
    "print('컬럼 별 고유 샘플의 수 : ({}, {})'.format(data['comments'].nunique(), data['label'].nunique())) # 중복 여부 확인\n",
    "data.drop_duplicates(subset=[\"comments\"], inplace=True) # 중복 제거\n",
    "print('중복 제거 후 총 샘플의 수 :',len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 레이블 값의 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  count\n",
      "0      0  97223\n",
      "1      1  89920\n"
     ]
    }
   ],
   "source": [
    "print(data.groupby('label').size().reset_index(name = 'count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null 값 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "\n",
      "comments    1\n",
      "label       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().values.any(), end=\"\\n\\n\") # Null 값 여부 확인\n",
    "print(data.isnull().sum()) # Null 값의 갯수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7807</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     comments  label\n",
       "7807      NaN      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['comments'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "data = data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
    "print(data.isnull().values.any()) # Null 값이 존재하는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187142\n"
     ]
    }
   ],
   "source": [
    "print(len(data)) # Null 값 제거후 샘플의 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한글, 공백 제외 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>정말 재밌다 연기도 좋고 디카프리오 짱</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>심쿵심쿵 미치네요이수혁땜에 잠 못자겠어요ㅠ자꾸 아른거림ㅠ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>하지만 이니후빨러들은 이런거 관심 하나도 없음</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>착한아이임당  용지 덮고</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>진짜 평점 믿으면 안된 다는 걸 현실로 보여주는 영화입니다 네티즌전문가 하나같이 영...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  label\n",
       "0                              정말 재밌다 연기도 좋고 디카프리오 짱      0\n",
       "1                    심쿵심쿵 미치네요이수혁땜에 잠 못자겠어요ㅠ자꾸 아른거림ㅠ      0\n",
       "2                          하지만 이니후빨러들은 이런거 관심 하나도 없음      1\n",
       "3                                      착한아이임당  용지 덮고      1\n",
       "4  진짜 평점 믿으면 안된 다는 걸 현실로 보여주는 영화입니다 네티즌전문가 하나같이 영...      0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['comments'] = data['comments'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comments    1021\n",
      "label          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data['comments'] = data['comments'].str.strip()\n",
    "data['comments'].replace('', np.nan, inplace=True)\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186121\n"
     ]
    }
   ],
   "source": [
    "data = data.dropna(how = 'any')\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 및 테스트 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[:150000]\n",
    "test_data = data[150000:]\n",
    "\n",
    "train_data.to_csv(\"../data/train.csv\", index=False)\n",
    "test_data.to_csv(\"../data/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 형태소 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphs_X_train = []\n",
    "morphs_X_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Khaiii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = KhaiiiApi()\n",
    "X_train, X_test = [], []\n",
    "\n",
    "for sentence in train_data[\"comments\"]:\n",
    "    temp = []\n",
    "    for word in api.analyze(sentence): # 토큰화\n",
    "        for morph in word.morphs:\n",
    "            if morph.lex not in stopwords: # 불용어 제거\n",
    "                temp.append(morph.lex)\n",
    "    X_train.append(temp)  \n",
    "    \n",
    "for sentence in test_data[\"comments\"]:\n",
    "    temp = []\n",
    "    for word in api.analyze(sentence): # 토큰화\n",
    "        for morph in word.morphs:\n",
    "            if morph.lex not in stopwords: # 불용어 제거\n",
    "                temp.append(morph.lex)\n",
    "    X_test.append(temp)\n",
    "    \n",
    "morphs_X_train.append(X_train)\n",
    "morphs_X_test.append(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "X_train, X_test = [], []\n",
    "\n",
    "for sentence in train_data['comments']:\n",
    "    temp = []\n",
    "    temp = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    temp = [word for word in temp if not word in stopwords] # 불용어 제거\n",
    "    X_train.append(temp)\n",
    "    \n",
    "for sentence in test_data['comments']:\n",
    "    temp = []\n",
    "    temp = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    temp = [word for word in temp if not word in stopwords] # 불용어 제거\n",
    "    X_test.append(temp)\n",
    "    \n",
    "morphs_X_train.append(X_train)\n",
    "morphs_X_test.append(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab()\n",
    "X_train, X_test = [], []\n",
    "\n",
    "for sentence in train_data['comments']:\n",
    "    temp = []\n",
    "    temp = mecab.morphs(sentence, stem=True) # 토큰화\n",
    "    temp = [word for word in temp if not word in stopwords] # 불용어 제거\n",
    "    X_train_mecab.append(temp)\n",
    "    \n",
    "for sentence in test_data['comments']:\n",
    "    temp = []\n",
    "    temp = mecab.morphs(sentence, stem=True) # 토큰화\n",
    "    temp = [word for word in temp if not word in stopwords] # 불용어 제거\n",
    "    X_test.append(temp)\n",
    "\n",
    "morphs_X_train.append(X_train)\n",
    "morphs_X_test.append(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정수 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "\n",
    "for morph in morphs_X_train:\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(morph)\n",
    "    tokens.append(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 빈도 수가 낮은 단어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 단어의 수와, 등장 빈도가 threshhold 미만인 단어의 수를 리턴\n",
    "def vocab_counts(data, threshold):\n",
    "    rare_cnt, total_cnt = 0, len(data.word_index) \n",
    "    \n",
    "    for key, value in data.word_counts.items():\n",
    "        if value < threshold:\n",
    "            rare_cnt = rare_cnt + 1\n",
    "        \n",
    "    return total_cnt, rare_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sizes = []\n",
    "\n",
    "for i in range(len(morphs_X_train)):\n",
    "    total_cnt, rare_cnt = vocab_counts(tokens[i], 3)\n",
    "    vocab_size = total_cnt - rare_cnt + 2\n",
    "    vocab_sizes.append(vocab_size)\n",
    "    # 빈도수가 2이하인 단어들을 제거한 단어 집합을 이용하여 정수 인코딩\n",
    "    tokenizer = Tokenizer(vocab_size, oov_token = 'OOV') \n",
    "    tokenizer.fit_on_texts(morphs_X_train[i])\n",
    "    morphs_X_train[i] = tokenizer.texts_to_sequences(morphs_X_train[i])\n",
    "    morphs_X_test[i] = tokenizer.texts_to_sequences(morphs_X_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(morphs_X_train[1]), len(morphs_X_test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphs_y_train = [np.array(train_data['label']) for i in range(len(morphs_X_train))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 빈 샘플 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(morphs_X_train)):\n",
    "    # 빈도수가 2이하인 단어들로만 구성되었던 샘플들은 현재 비어 있기 때문에 해당 샘플들을 제거\n",
    "    drop_morph = [index for index, sentence in enumerate(morphs_X_train[i]) if len(sentence) < 1]\n",
    "    morphs_X_train[i] = np.delete(morphs_X_train[i], drop_morph, axis=0)\n",
    "    morphs_y_train[i] = np.delete(morphs_y_train[i], drop_morph, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(morphs_X_train[2]), len(morphs_y_train[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(morphs_X_train)):\n",
    "    morphs_X_train[i] = pad_sequences(morphs_X_train[i], 45)\n",
    "    morphs_X_test[i] = pad_sequences(morphs_X_test[i], 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리된 데이터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/pickle/khaiii_X_train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(morphs_X_train[0], f)\n",
    "\n",
    "with open(\"../data/pickle/khaiii_y_train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(morphs_y_train[0], f)\n",
    "    \n",
    "with open(\"../data/pickle/khaiii_X_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(morphs_X_test[0], f)\n",
    "    \n",
    "    \n",
    "with open(\"../data/pickle/okt_train_X.pkl\", \"wb\") as f:\n",
    "    pickle.dump(morphs_X_train[1], f)\n",
    "\n",
    "with open(\"../data/pickle/okt_train_y.pkl\", \"wb\") as f:\n",
    "    pickle.dump(morphs_y_train[1], f)\n",
    "    \n",
    "with open(\"../data/pickle/okt_test_X.pkl\", \"wb\") as f:\n",
    "    pickle.dump(morphs_X_test[1], f)\n",
    "\n",
    "\n",
    "with open(\"../data/pickle/mecab_train_X.pkl\", \"wb\") as f:\n",
    "    pickle.dump(morphs_X_train[2], f)\n",
    "\n",
    "with open(\"../data/pickle/mecab_train_y.pkl\", \"wb\") as f:\n",
    "    pickle.dump(morphs_y_train[2], f)\n",
    "    \n",
    "with open(\"../data/pickle/mecab_test_X.pkl\", \"wb\") as f:\n",
    "    pickle.dump(morphs_X_test[2], f)\n",
    "    \n",
    "\n",
    "with open(\"../data/pickle/vocab_sizes.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vocab_sizes, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
